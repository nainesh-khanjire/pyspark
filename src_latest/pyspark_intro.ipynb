{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0395152e-1398-430a-8b6f-a6a55a90528d",
   "metadata": {},
   "source": [
    "used for parallel data processing only, data is not stored anywehre.\n",
    "1. spark SQL\n",
    "2. streaming\n",
    "3. MLlib\n",
    "4. Graphx\n",
    "5. SparkR\n",
    "   spark is written in scala\n",
    "\n",
    "## Main components\n",
    "   ### spark session (master node/Driver) >> cluster manager >> executor/worker node\n",
    "\n",
    "  this processing happens on unified (ANYONE CAN USE SAME COMPUTER)computer cluster\n",
    "  master node > slave node\n",
    "              > slave node\n",
    "\n",
    "data is processed in RAM, using lazy evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1503c73-07e7-41a2-a132-afc7acd9eb19",
   "metadata": {},
   "source": [
    "previously data format was tabular\n",
    "then file, text, csv, image, video, audio format data was introduced\n",
    "structured data: key value system\n",
    "\n",
    "## 3 v's of big data > \n",
    "1. velocity > 1 sec, 1 hour\n",
    "2. volume > 5GB, 10TB\n",
    "3. variety > structured, semi structured, unstructured\n",
    "\n",
    "ETL, ELT\n",
    "\n",
    "issues of handling big data > storage, processing (ram, cpu)\n",
    "\n",
    "## 2 options : \n",
    "1. Monolithic approach > vertical scaling, expensive, low availability\n",
    "2. Distributed approach > horizonatl scaling, economical, highly available\n",
    "\n",
    "## HADOOP :\n",
    "1. hadoop also uses ram, it is slow because i writes data to disk and reads back from disk to memory.\n",
    "if it does not write and read back from disk then it wont matter\n",
    "\n",
    "2. Batch data processing\n",
    "3. difficult to write code in hadoop\n",
    "4. more secure with kerberos authentication, ACL (access control list) authorization\n",
    "YARN > kerberos\n",
    "5. fault tolerance >. it has block of data and replication factor to handle the failure\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## SPARK :\n",
    "1. spark is faster because it does all the computation in ram (in memory), it writes data in memory in ram of the executor\n",
    "2. both streaming and batch data processing\n",
    "3. easy to write code, also can be written inn depth\n",
    "4. uses HDFS storage, ,ACL > kerberos > less secure\n",
    "5. uses directed acyclic graph DAG > RDD which is immutable, it knows how the process is created using dag\n",
    "\n",
    "## Libraries for high level api:\n",
    "datatframe spark sql, streaming, ML lib, GraphX >> dataframe\n",
    "## low level api: spark core\n",
    "python, java, R, scala >> RDD (not used nowadays)\n",
    "\n",
    "everything is under spark engine\n",
    "\n",
    "\n",
    "spark core >> java wrapper >> python wrapper|\n",
    "there is no pyspark driver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618bc0ad-41c0-4cc2-bc55-82f5f01d35a6",
   "metadata": {},
   "source": [
    "if python udf used in pyspark code, > udf is not optimized, we need python worker to execute them, which is time consuming\n",
    "> so use inbuilt functions as much as possible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb3ceaa-e4e1-42c0-85d2-81d4c440bc1a",
   "metadata": {},
   "source": [
    "## TRANSFORMATION in pyspark "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29afa277-ac9e-4ca9-b989-c88bf86ff94e",
   "metadata": {},
   "source": [
    "> narrow dependency transformation\n",
    "\n",
    "1. transformations which are not dependent on any other partition called narrow dependency\n",
    "2. example: filter, select, union, map() etc\n",
    "3. example: show me people with age > 18\n",
    "   \n",
    "> wide dependency transformation\n",
    "1. this needs data to be used from 1 partition to other and it is dependent on other partitions as well\n",
    "2. avoid wide transformations as much as possible because they are expensive to execute\n",
    "3. example: sum of everyones total salary, where data is partitioned, here data needs to be shuffled\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88eb5d37-724f-4beb-ab33-9022c4ffd49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1d9b4b3-5cb2-43b2-8328-958664240e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://zephyrus:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>flights</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2067e7491f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"flights\").getOrCreate() \n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b54a4af-4152-434d-8412-1a542438a2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year',\n",
       " 'Month',\n",
       " 'DayofMonth',\n",
       " 'DayOfWeek',\n",
       " 'DepTime',\n",
       " 'CRSDepTime',\n",
       " 'ArrTime',\n",
       " 'CRSArrTime',\n",
       " 'UniqueCarrier',\n",
       " 'FlightNum',\n",
       " 'TailNum',\n",
       " 'ActualElapsedTime',\n",
       " 'CRSElapsedTime',\n",
       " 'AirTime',\n",
       " 'ArrDelay',\n",
       " 'DepDelay',\n",
       " 'Origin',\n",
       " 'Dest',\n",
       " 'Distance',\n",
       " 'TaxiIn',\n",
       " 'TaxiOut',\n",
       " 'Cancelled',\n",
       " 'CancellationCode',\n",
       " 'Diverted',\n",
       " 'CarrierDelay',\n",
       " 'WeatherDelay',\n",
       " 'NASDelay',\n",
       " 'SecurityDelay',\n",
       " 'LateAircraftDelay']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"../data/flights.csv\")\n",
    "flights.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36b1875c-6884-4ed3-9701-590ec55a0bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flights.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79fce3a3-b513-4d04-a814-784465928a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_data_partition = flights.repartition(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da5d7fbf-eef1-4596-8bd0-45088f671512",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_india_data = flights.filter(\"Dest=='IND'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0de81a-d68a-415f-b8b2-88631a6b085f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6d569-fc39-4787-aa04-42c533e90b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a3e77a-6e53-472d-ba2a-29325dec02f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba73de3-28ea-449a-9f3f-a7b2d169ab33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22508507-fe95-40dc-83b8-4ae12eb4a7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1245a-7caf-4add-b4ea-60c758f81182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76358dbc-1889-4439-a063-6990d5e2ce59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd63645-f749-4f15-bb1d-c98ca999012b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24343aa-a489-4165-9a3a-9e2a8f4d9845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b9f3f-47e3-4628-b5bd-7923e9c06508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a9f6d-2375-4197-89dd-be93b8597d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89366fd1-794c-4f68-89d2-68f0eeb23fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cef848-b34c-4e21-a093-ef8aff3ddbec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bea8e2-e339-4d7c-8f7e-c20af8a2b247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039cb08f-f943-4797-be2c-2b87eeb0e2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6e39b7-0f22-49b1-b20e-6e66324686f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d540d75d-0833-4ba3-bbe9-e52cc34d3f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd15269-595e-441b-9350-3fe911b79548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485e6ea-51fd-41c4-ac84-11d95f9f3cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340729c-5f14-4e5d-9f48-cf357eaf08d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc6c85-87fa-4aae-bdec-4ab2cd5ba35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee9ecf-e961-40f2-929a-4d46abf699b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402121d7-3215-49f6-85ae-0dc5e22dfaf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b63d56-d698-4bed-bd9f-2c5800bb8798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154c6df-bd19-4b5a-8e2b-194dbb1ebeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404e9b1-98b5-48d1-a1a1-e311e1152930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cda1f1-8e48-46d4-9e67-fef998f433ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f036e9d-0451-44ba-a188-eb55b5e24234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828a95f-8cec-44de-a35c-8aeebf65c7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b138b400-5115-4582-aaf3-194ec58843fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b49dd6d-756e-4db2-bee9-519dd19e20a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0bb435-db57-4a29-961a-021a31629123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52eccc-ba67-4df4-a9f8-b41c3722afac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09a374-aa04-4a31-8cf9-d46b3474a51f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e86897-d1bb-482e-aa81-0d60830fd19b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbdf97f-3740-4de0-b05a-670fb9dd4a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYSPARK_KERNEL",
   "language": "python",
   "name": "pyspark_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
